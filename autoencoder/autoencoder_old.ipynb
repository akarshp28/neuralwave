{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2GEa2q7o9y6S"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import h5py\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#Limit available GPUs to 1 (first gpu)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EFXx-_ScrHTz"
   },
   "source": [
    "##### **Data Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5mqic5dIU4Jn"
   },
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    #initialize variables\n",
    "    def __init__(self, dataset_path, shape, shuffle=True):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.datapaths = list()\n",
    "        self.labels = list()\n",
    "        self.read_samples()\n",
    "        self.num_sample = len(self.datapaths)\n",
    "        self.shape = shape\n",
    "      \n",
    "    #populate lists with csv file paths and their corresponding labels from dataset dir\n",
    "    #dataset folder should be organised as following\n",
    "    #data_path\n",
    "    #    class 1\n",
    "    #        sample 1\n",
    "    #        sample 2\n",
    "    #            .\n",
    "    #            .\n",
    "    #            .\n",
    "    #    class 2\n",
    "    #        sample 1\n",
    "    #        sample 2\n",
    "    #            .\n",
    "    #            .\n",
    "    #            .\n",
    "    #\n",
    "    def read_samples(self):\n",
    "        label = 0\n",
    "\n",
    "        classes = sorted(os.walk(self.dataset_path).__next__()[1])\n",
    "\n",
    "        # List each sub-directory (the classes)\n",
    "        for c in classes:\n",
    "            c_dir = os.path.join(self.dataset_path, c)\n",
    "            walk = os.walk(c_dir).__next__()\n",
    "            # Add each image to the training set\n",
    "            for sample in walk[2]:\n",
    "                # Only keeps csv samples\n",
    "                if sample.endswith('.csv'):\n",
    "                    self.datapaths.append(os.path.join(c_dir, sample))\n",
    "                    self.labels.append(label)\n",
    "            label += 1\n",
    "            \n",
    "    #shuffle data paths along with their labels together\n",
    "    def combined_shuffle(self):\n",
    "        combined = list(zip(self.datapaths, self.labels ))\n",
    "        random.shuffle(combined)\n",
    "        self.datapaths[:], self.labels [:] = zip(*combined)\n",
    "    \n",
    "    #function called by the tensorflow object\n",
    "    #returns pairs of numpy arrays read from csv files along with their labels\n",
    "    def __iter__(self):\n",
    "        if shuffle:\n",
    "            self.combined_shuffle()\n",
    "\n",
    "        for i in range(self.num_sample):\n",
    "            data = np.loadtxt(open(self.datapaths[i], \"rb\"), delimiter=\",\")\n",
    "            label = self.labels[i]\n",
    "            if data.shape == self.shape:\n",
    "                yield data, label\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_AwoDnr6rBn_"
   },
   "source": [
    "# **Seq2Seq Autoencoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0dluPE86w7qB"
   },
   "outputs": [],
   "source": [
    "#Seq2Seq Autoencoder with a single LSTM for both encoder and decoder,\n",
    "#along with optional rollout for the decoder LSTM\n",
    "def autoencoder(inputs, reuse, sequence_length, input_width, rollout):\n",
    "    \n",
    "    def encoder_loop_fn(time, cell_output, cell_state, loop_state):\n",
    "        emit_output = cell_output  # == None for time == 0\n",
    "\n",
    "        #Bool to check if sequence is over\n",
    "        elements_finished = (time >= sequence_length)\n",
    "        finished = tf.reduce_all(elements_finished)\n",
    "        \n",
    "        if cell_output is None:  # time == 0\n",
    "            next_cell_state = encoder_cell.zero_state(batch_size, tf.float32)\n",
    "        else:\n",
    "            next_cell_state = cell_state\n",
    "  \n",
    "        #Bool to check if sequence is over\n",
    "        elements_finished = (time >= sequence_length)\n",
    "        finished = tf.reduce_all(elements_finished)\n",
    "        \n",
    "        #input to lstm at each time step        \n",
    "        next_input = tf.cond(finished,\n",
    "                             lambda: tf.zeros([batch_size, input_width], dtype=tf.float32),\n",
    "                             lambda: inputs_ta.read(time))\n",
    "\n",
    "        next_loop_state = None\n",
    "\n",
    "        return (elements_finished, next_input, next_cell_state, emit_output, next_loop_state)\n",
    "\n",
    "    def decoder_loop_fn(time, cell_output, cell_state, loop_state):\n",
    "        emit_output = cell_output  # == None for time == 0\n",
    "        \n",
    "        #Bool to check if sequence is over\n",
    "        elements_finished = (time >= sequence_length)\n",
    " \n",
    "        #input to lstm at each time step, cell state   \n",
    "        if cell_output is None:\n",
    "            next_cell_state = encoder_cell_states\n",
    "            next_input = tf.zeros([batch_size, input_width], dtype=tf.float32)\n",
    "        else:\n",
    "            next_cell_state = cell_state\n",
    "            next_input = tf.cond(rollout,\n",
    "                                 lambda: cell_output,\n",
    "                                 lambda: inputs_ta.read(time-1))   \n",
    "            \n",
    "            next_input.set_shape([batch_size, input_width])\n",
    "            \n",
    "        next_loop_state = None\n",
    "\n",
    "        return (elements_finished, next_input, next_cell_state, emit_output, next_loop_state)  \n",
    "    \n",
    "    \n",
    "    # Define a scope for reusing the variables\n",
    "    with tf.variable_scope('autoencoder', reuse=reuse):\n",
    "\n",
    "        #convert sample into tensor array\n",
    "        inputs_ta = tf.TensorArray(dtype=tf.float32, size=sequence_length, clear_after_read=False)\n",
    "        inputs_ta = inputs_ta.unstack(inputs)\n",
    "\n",
    "        with tf.name_scope('encoder'):\n",
    "            #encoder lstm\n",
    "            encoder_cell = tf.contrib.rnn.LSTMCell(input_width)\n",
    "            _, encoder_cell_states, _ = tf.nn.raw_rnn(encoder_cell, encoder_loop_fn)\n",
    "\n",
    "        with tf.name_scope('decoder'):\n",
    "            #decoder lstm\n",
    "            decoder_cell = tf.contrib.rnn.LSTMCell(input_width)\n",
    "            decoder_hidden_states_ta, _, _ = tf.nn.raw_rnn(decoder_cell, decoder_loop_fn)\n",
    "\n",
    "        #convert lstm output array into a tensor\n",
    "        outputs = decoder_hidden_states_ta.stack()\n",
    "\n",
    "        return outputs, encoder_cell_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RyzBPgnjq82Y"
   },
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "78GBR4pY2vsz"
   },
   "outputs": [],
   "source": [
    "data_path = \"/home/kalvik/shared/CSI_DATA/preprocessed_final/train\"\n",
    "initial_learning_rate = 0.001\n",
    "rollout_status = False\n",
    "sequence_length = 8000\n",
    "input_width = 540\n",
    "decay_rate = 0.6\n",
    "batch_size = 8\n",
    "data_steps = 850\n",
    "data_steps = data_steps//batch_size\n",
    "decay_steps = data_steps-1\n",
    "rollout_step = data_steps-1\n",
    "save_epoch = 2\n",
    "epochs = 10\n",
    "\n",
    "#reset graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope('input'):\n",
    "    # Graph input and label\n",
    "    gen = Generator(data_path, (sequence_length, input_width))\n",
    "    dataset = tf.data.Dataset().from_generator(lambda: gen, output_types=(tf.float32), output_shapes=(sequence_length, input_width)).prefetch(2 * batch_size).batch(batch_size)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    inputs = iterator.get_next()\n",
    "    inputs = tf.transpose(inputs, perm=[1, 0, 2])\n",
    "\n",
    "with tf.name_scope('rollout'):\n",
    "    #variable to control rnn rollout\n",
    "    rollout = tf.placeholder(tf.bool)\n",
    "\n",
    "# autoencoder model\n",
    "outputs, _ = autoencoder(inputs=inputs, \n",
    "                         reuse=tf.AUTO_REUSE, \n",
    "                         sequence_length=sequence_length, \n",
    "                         input_width=input_width,\n",
    "                         rollout=rollout)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    # Define loss\n",
    "    loss_op = tf.reduce_mean(tf.square(inputs - outputs))\n",
    "    tf.summary.scalar(\"loss\", loss_op) \n",
    "\n",
    "with tf.name_scope('optimizer'):\n",
    "    #global step counter\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    \n",
    "    #learning rate decay\n",
    "    learning_rate = tf.train.exponential_decay(initial_learning_rate, \n",
    "                                               global_step, \n",
    "                                               decay_steps, \n",
    "                                               decay_rate, \n",
    "                                               staircase=True) \n",
    "    tf.summary.scalar(\"learning_rate\", learning_rate)\n",
    "    \n",
    "    #adam optimizer\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op, global_step=global_step) \n",
    "\n",
    "# Initialize the variables, model saver, merge tensorboard summaries\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(max_to_keep=10)\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "print(\"Training\")\n",
    "# Start\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    \n",
    "    #tensorboard writer\n",
    "    writer = tf.summary.FileWriter('/home/kalvik/shared/autoencoder/tensorboard/train', sess.graph)\n",
    "\n",
    "    # Keep training until reach max iterations\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for step in range(1, data_steps + 1):\n",
    "\n",
    "            # Run optimization op (backprop)\n",
    "            _, loss, summary = sess.run([train_op, loss_op, merged], feed_dict={rollout:rollout_status})\n",
    "            writer.add_summary(summary, ((epoch-1) * data_steps) + step)\n",
    "           \n",
    "            #Print loss\n",
    "            sys.stdout.write(\"\\rEpoch: {}, Mini Batch: {}, Loss: {:.4f}\".format(epoch, step, loss))\n",
    "            sys.stdout.flush()\n",
    "                \n",
    "            #change rollout status\n",
    "            if step % rollout_step == 0:\n",
    "                rollout_status = not rollout_status\n",
    "                print(\"Rollout status : {}\".format(rollout_status))\n",
    "                \n",
    "        print(\"\\n\")\n",
    "                \n",
    "        #save model\n",
    "        if epoch % save_epoch == 0:\n",
    "            saver.save(sess, '/home/kalvik/shared/autoencoder/weights/autoencoder_loss-{}_epoch-{}'.format(loss, epoch), global_step=(((epoch-1) * data_steps) + step))\n",
    "    \n",
    "    #save model\n",
    "    saver.save(sess, '/home/kalvik/shared/autoencoder/weights/autoencoder_loss-{}_epoch-{}'.format(loss, epoch), global_step=((epoch-1) * data_steps) + step)\n",
    "\n",
    "    print(\"Finished!\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Elami3goq4XN"
   },
   "source": [
    "# **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "F86G17WAU4KA"
   },
   "outputs": [],
   "source": [
    "data_path = \"/home/kalvik/shared/CSI_DATA/preprocessed_final/test\"\n",
    "rollout_status = True\n",
    "sequence_length = 8000\n",
    "input_width = 540\n",
    "batch_size = 8\n",
    "data_steps = 150\n",
    "data_steps = data_steps//batch_size\n",
    "\n",
    "#reset graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope('input'):\n",
    "    # Graph input and label\n",
    "    gen = Generator(data_path, (sequence_length, input_width))\n",
    "    dataset = tf.data.Dataset().from_generator(lambda: gen, output_types=(tf.float32), output_shapes=(sequence_length, input_width)).prefetch(2 * batch_size).batch(batch_size)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    inputs = iterator.get_next()\n",
    "    inputs = tf.transpose(inputs, perm=[1, 0, 2])\n",
    "\n",
    "with tf.name_scope('rollout'):\n",
    "    #variable to control rnn rollout\n",
    "    rollout = tf.placeholder(tf.bool)\n",
    "\n",
    "# autoencoder model\n",
    "outputs, _ = autoencoder(inputs=inputs, \n",
    "                         reuse=tf.AUTO_REUSE, \n",
    "                         sequence_length=sequence_length, \n",
    "                         input_width=input_width,\n",
    "                         rollout=rollout)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    # Define loss\n",
    "    loss_op = tf.reduce_mean(tf.square(inputs - outputs))\n",
    "    tf.summary.scalar(\"loss\", loss_op) \n",
    "\n",
    "# Initialize the variables, model saver, merge tensorboard summaries\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(max_to_keep=10)\n",
    "checkpoint = tf.train.latest_checkpoint('weights')\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "print(\"Testing\")\n",
    "# Start\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    \n",
    "    #load model weights from checkpoint\n",
    "    saver.restore(sess, checkpoint)\n",
    "    \n",
    "    #tensorboard writer\n",
    "    writer = tf.summary.FileWriter('/home/kalvik/shared/autoencoder/tensorboard/test', sess.graph)\n",
    "\n",
    "    for step in range(1, data_steps + 1):\n",
    "\n",
    "        # Run optimization op (backprop)\n",
    "        loss, summary = sess.run([loss_op, merged], feed_dict={rollout:rollout_status})\n",
    "        writer.add_summary(summary, step)\n",
    "        print(\"Mini Batch: {}, Loss: {:.4f}\".format(step, loss))\n",
    "\n",
    "    print(\"Finished!\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VQ3I8gdIqlow"
   },
   "source": [
    "# **Sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wcpqU6v4U4KJ"
   },
   "outputs": [],
   "source": [
    "encoded_X = []\n",
    "encoded_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "n3Jri53bU4KO"
   },
   "outputs": [],
   "source": [
    "data_path = \"/home/kalvik/shared/CSI_DATA/preprocessed_final/test\"\n",
    "rollout_status = True\n",
    "sequence_length = 8000\n",
    "input_width = 540\n",
    "batch_size = 8\n",
    "data_steps = 150\n",
    "data_steps = data_steps//batch_size\n",
    "\n",
    "#reset graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope('input'):\n",
    "    # Graph input\n",
    "    gen = Generator(data_path, (sequence_length, input_width), shuffle=False)\n",
    "    dataset = tf.data.Dataset().from_generator(lambda: gen, output_types=(tf.float32, tf.int32)).prefetch(2 * batch_size).batch(batch_size)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    inputs, labels = iterator.get_next()\n",
    "    inputs.set_shape([None, sequence_length, input_width])\n",
    "    inputs = tf.transpose(inputs, perm=[1, 0, 2])\n",
    "\n",
    "with tf.name_scope('rollout'):\n",
    "    #variable to control rnn rollout\n",
    "    rollout = tf.placeholder(tf.bool)\n",
    "\n",
    "# autoencoder model\n",
    "_, encoder_cell_states = autoencoder(inputs=inputs, \n",
    "                         reuse=tf.AUTO_REUSE, \n",
    "                         sequence_length=sequence_length, \n",
    "                         input_width=input_width,\n",
    "                         rollout=rollout)\n",
    "\n",
    "# Initialize the variables, model saver\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(max_to_keep=10)\n",
    "checkpoint = tf.train.latest_checkpoint('weights')\n",
    "\n",
    "print(\"Sampling\")\n",
    "# Start\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    \n",
    "    #load model weights\n",
    "    saver.restore(sess, checkpoint)\n",
    "    \n",
    "    for step in range(data_steps):\n",
    "        # Run optimization op (backprop)\n",
    "        X, y = sess.run([encoder_cell_states, labels], feed_dict={rollout:rollout_status})\n",
    "\n",
    "        sys.stdout.write(\"\\r{}% complete\".format((step/data_steps)*100))\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        encoded_X.append(X)\n",
    "        encoded_y.append(y)\n",
    "\n",
    "    print(\"Finished!\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3sIw9nRLrP7t"
   },
   "outputs": [],
   "source": [
    "data_path = \"/home/kalvik/shared/CSI_DATA/preprocessed_final/train\"\n",
    "rollout_status = True\n",
    "sequence_length = 8000\n",
    "input_width = 540\n",
    "batch_size = 8\n",
    "data_steps = 150\n",
    "data_steps = data_steps//batch_size\n",
    "\n",
    "#reset graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope('input'):\n",
    "    # Graph input\n",
    "    gen = Generator(data_path, (sequence_length, input_width), shuffle=False)\n",
    "    dataset = tf.data.Dataset().from_generator(lambda: gen, output_types=(tf.float32, tf.int32)).prefetch(2 * batch_size).batch(batch_size)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    inputs, labels = iterator.get_next()\n",
    "    inputs.set_shape([None, sequence_length, input_width])\n",
    "    inputs = tf.transpose(inputs, perm=[1, 0, 2])\n",
    "\n",
    "with tf.name_scope('rollout'):\n",
    "    #variable to control rnn rollout\n",
    "    rollout = tf.placeholder(tf.bool)\n",
    "\n",
    "# autoencoder model\n",
    "_, encoder_cell_states = autoencoder(inputs=inputs, \n",
    "                         reuse=tf.AUTO_REUSE, \n",
    "                         sequence_length=sequence_length, \n",
    "                         input_width=input_width,\n",
    "                         rollout=rollout)\n",
    "\n",
    "# Initialize the variables, model saver\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(max_to_keep=10)\n",
    "checkpoint = tf.train.latest_checkpoint('weights')\n",
    "\n",
    "print(\"Sampling\")\n",
    "# Start\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    \n",
    "    #load model weights\n",
    "    saver.restore(sess, checkpoint)\n",
    "    \n",
    "    for step in range(data_steps):\n",
    "        # Run optimization op (backprop)\n",
    "        X, y = sess.run([encoder_cell_states, labels], feed_dict={rollout:rollout_status})\n",
    "\n",
    "        sys.stdout.write(\"\\r{}% complete\".format((step/data_steps)*100))\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        encoded_X.append(X)\n",
    "        encoded_y.append(y)\n",
    "\n",
    "    print(\"Finished!\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5A5pXRkMsb51"
   },
   "source": [
    "# **Saving Encoded Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "to-AeWoxrYti"
   },
   "outputs": [],
   "source": [
    "encoded_X = np.array(encoded_X)\n",
    "encoded_y = np.array(encoded_y)\n",
    "\n",
    "print(encoded_X.shape, encoded_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sBYo6Zjyrh5r"
   },
   "outputs": [],
   "source": [
    "hf = h5py.File('encoded_dataset.h5', 'w')\n",
    "hf.create_dataset('data', data=encoded_X)\n",
    "hf.create_dataset('labels', data=encoded_y)\n",
    "hf.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "autoencoder.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
