{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2GEa2q7o9y6S"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5mqic5dIU4Jn"
   },
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    #initialize variables\n",
    "    def __init__(self, dataset_path, shape, shuffle=True):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.datapaths = list()\n",
    "        self.labels = list()\n",
    "        self.read_samples()\n",
    "        self.num_sample = len(self.datapaths)\n",
    "        self.shape = shape\n",
    "        self.shuffle=shuffle\n",
    "      \n",
    "    #populate lists with csv file paths and their corresponding labels from dataset dir\n",
    "    #dataset folder should be organised as following\n",
    "    #data_path\n",
    "    #    class 1\n",
    "    #        sample 1\n",
    "    #        sample 2\n",
    "    #            .\n",
    "    #            .\n",
    "    #            .\n",
    "    #    class 2\n",
    "    #        sample 1\n",
    "    #        sample 2\n",
    "    #            .\n",
    "    #            .\n",
    "    #            .\n",
    "    #\n",
    "    def read_samples(self):\n",
    "        label = 0\n",
    "\n",
    "        classes = sorted(os.walk(self.dataset_path).__next__()[1])\n",
    "\n",
    "        # List each sub-directory (the classes)\n",
    "        for c in classes:\n",
    "            c_dir = os.path.join(self.dataset_path, c)\n",
    "            walk = os.walk(c_dir).__next__()\n",
    "            # Add each image to the training set\n",
    "            for sample in walk[2]:\n",
    "                # Only keeps csv samples\n",
    "                if sample.endswith('.csv'):\n",
    "                    self.datapaths.append(os.path.join(c_dir, sample))\n",
    "                    self.labels.append(label)\n",
    "            label += 1\n",
    "            \n",
    "    #shuffle data paths along with their labels together\n",
    "    def combined_shuffle(self):\n",
    "        combined = list(zip(self.datapaths, self.labels ))\n",
    "        random.shuffle(combined)\n",
    "        self.datapaths[:], self.labels [:] = zip(*combined)\n",
    "    \n",
    "    #function called by the tensorflow object\n",
    "    #returns pairs of numpy arrays read from csv files along with their labels\n",
    "    def __iter__(self):\n",
    "        self.combined_shuffle()\n",
    "        for i in range(self.num_sample):\n",
    "            data = np.loadtxt(open(self.datapaths[i], \"rb\"), delimiter=\",\")\n",
    "            data_mid = int(data.shape[0]/2)\n",
    "            data = data[data_mid-int(self.shape[0]/2):data_mid+int(self.shape[0]/2)]\n",
    "            label = self.labels[i]\n",
    "            if data.shape == self.shape:\n",
    "                yield data, label\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(time):\n",
    "    if time < 60:\n",
    "        string = \"{:.0f}s\".format(time)\n",
    "    elif time < 3600:\n",
    "        string = \"{:.0f}m\".format(time/60)\n",
    "    else:\n",
    "        string = \"{:.2f}h\".format(time/60/60)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py#L101\n",
    "def average_gradients(tower_grads):\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "\n",
    "        # Note that each grad_and_vars looks like the following:\n",
    "        #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n",
    "        grads = [g for g, _ in grad_and_vars]\n",
    "        grad = tf.reduce_mean(grads, 0)\n",
    "\n",
    "        # Keep in mind that the Variables are redundant because they are shared\n",
    "        # across towers. So .. we will just return the first tower's pointer to\n",
    "        # the Variable.\n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "        average_grads.append(grad_and_var)\n",
    "    return average_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0dluPE86w7qB"
   },
   "outputs": [],
   "source": [
    "#Seq2Seq Autoencoder with a single LSTM for both encoder and decoder,\n",
    "#along with optional rollout for the decoder LSTM\n",
    "def autoencoder(i, inputs, rollout):\n",
    "    \n",
    "    def encoder_loop_fn(time, cell_output, cell_state, loop_state):\n",
    "        emit_output = cell_output  # == None for time == 0\n",
    "        \n",
    "        if cell_output is None:  # time == 0\n",
    "            next_cell_state = encoder_cell.zero_state(batch_size, tf.float32)\n",
    "        else:\n",
    "            next_cell_state = cell_state\n",
    "            \n",
    "        elements_finished = (time >= sequence_length)\n",
    "        finished = tf.reduce_all(elements_finished)\n",
    "        \n",
    "        next_input = tf.cond(finished,\n",
    "                             lambda: tf.zeros([batch_size, input_width], dtype=tf.float32),\n",
    "                             lambda: inputs_ta.read(time))\n",
    "        \n",
    "        next_loop_state = None\n",
    "        return (elements_finished, next_input, next_cell_state, emit_output, next_loop_state)\n",
    "\n",
    "\n",
    "    def decoder_loop_fn(time, cell_output, cell_state, loop_state):         \n",
    "        emit_output = cell_output\n",
    "        \n",
    "        if cell_output is None:  # time == 0\n",
    "            next_cell_state = encoder_cell_states\n",
    "            next_input = tf.zeros([batch_size, input_width], dtype=tf.float32)\n",
    "        else:\n",
    "            next_cell_state = cell_state\n",
    "            next_input = tf.cond(rollout,\n",
    "                                 lambda: tf.layers.dense(cell_output, input_width, activation=tf.nn.sigmoid, name=\"FC1\", reuse=tf.AUTO_REUSE), \n",
    "                                 lambda: inputs_ta.read(time-1))\n",
    "            \n",
    "        elements_finished = (time >= sequence_length)\n",
    "        \n",
    "        next_loop_state = None\n",
    "        return (elements_finished, next_input, next_cell_state, emit_output, next_loop_state)\n",
    "\n",
    "    with tf.name_scope('autoencoder_{}'.format(i)):\n",
    "        #convert sample into tensor array\n",
    "        inputs_ta = tf.TensorArray(dtype=tf.float32, size=sequence_length, clear_after_read=False)\n",
    "        inputs_ta = inputs_ta.unstack(inputs)\n",
    "\n",
    "        with tf.name_scope('encoder'):\n",
    "            #encoder lstm\n",
    "            encoder_cell = tf.contrib.rnn.LSTMCell(lstm_size)\n",
    "            _, encoder_cell_states, _ = tf.nn.raw_rnn(encoder_cell, encoder_loop_fn)\n",
    "\n",
    "        with tf.name_scope('decoder'):\n",
    "            #decoder lstm\n",
    "            decoder_cell = tf.contrib.rnn.LSTMCell(lstm_size)\n",
    "            decoder_hidden_states_ta, _, _ = tf.nn.raw_rnn(decoder_cell, decoder_loop_fn)\n",
    "\n",
    "        #convert lstm output array into a tensor\n",
    "        outputs = decoder_hidden_states_ta.stack()\n",
    "        outputs = tf.layers.dense(outputs, input_width, activation=tf.nn.sigmoid, name=\"FC1\", reuse=tf.AUTO_REUSE)\n",
    "\n",
    "    with tf.name_scope(\"loss_{}\".format(i)):       \n",
    "        loss = tf.reduce_mean(tf.square(inputs-outputs))\n",
    "    \n",
    "    return outputs, encoder_cell_states, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    learning_rate = tf.train.exponential_decay(lr, \n",
    "                                               global_step, \n",
    "                                               decay_steps, \n",
    "                                               decay_rate, \n",
    "                                               staircase=True) \n",
    "    tf.summary.scalar(\"learning_rate\", learning_rate)\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "    rollout = tf.constant(rollout_, dtype=tf.bool)\n",
    "    \n",
    "    dataset = tf.data.Dataset().from_generator(lambda: gen, output_types=(tf.float32, tf.int32)).prefetch(2 * batch_size * num_gpus).batch(batch_size).repeat(count=None)\n",
    "    iterator = dataset.make_one_shot_iterator()  \n",
    "\n",
    "    tower_grads = []\n",
    "    losses = []\n",
    "\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE):\n",
    "        for i in range(num_gpus):\n",
    "            with tf.device('/gpu:%d' % i):\n",
    "                with tf.name_scope('Tower_%d' % (i)) as scope:\n",
    "                    # Dequeues one batch for the GPU\n",
    "                    inputs, labels = iterator.get_next()\n",
    "                    inputs = tf.transpose(inputs, perm=[2, 0, 1])\n",
    "                    inputs.set_shape([sequence_length, batch_size, input_width])\n",
    "\n",
    "                    loss, encoder_cell_states = autoencoder(i, inputs, rollout)\n",
    "                    grads = opt.compute_gradients(loss)\n",
    "                    tower_grads.append(grads)\n",
    "                    losses.append(loss)\n",
    "\n",
    "    gradients = average_gradients(tower_grads)\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    apply_gradient_op = opt.apply_gradients(gradients, global_step)\n",
    "    \n",
    "    avg_loss = tf.reduce_mean(losses)\n",
    "    tf.summary.scalar(\"avg_loss\", avg_loss) \n",
    "\n",
    "    saver = tf.train.Saver(tf.global_variables(), max_to_keep=5)\n",
    "    merged = tf.summary.merge_all()\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    return init, merged, saver, avg_loss, apply_gradient_op, encoder_cell_states, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Training\n",
    "data_path = \"/home/kalvik/shared/CSI_DATA/preprocessed_final/train\"\n",
    "weight_path = \"/home/kalvik/shared/autoencoder/weights/mse/\"\n",
    "tensorboard_path = \"/home/kalvik/shared/autoencoder/tensorboard/train_mse_8000_4000\"\n",
    "sequence_length = 540\n",
    "input_width = 8000 \n",
    "decay_rate = 0.9\n",
    "lstm_size = 4000\n",
    "rollout_ = False\n",
    "batch_size = 8\n",
    "save_epoch = 5\n",
    "num_gpus = 4\n",
    "epochs = 5\n",
    "lr = 5E-4\n",
    "gen = Generator(data_path, (input_width, sequence_length), shuffle=True)\n",
    "data_steps = int(gen.num_sample//(batch_size*num_gpus))\n",
    "decay_steps = data_steps\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default(), tf.device('/cpu:0'):\n",
    "    init, merged, saver, avg_loss, apply_gradient_op, encoded_data, encoded_labels = model()\n",
    "\n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        if tf.train.latest_checkpoint(weight_path) != None:\n",
    "            saver.restore(sess, tf.train.latest_checkpoint(weight_path))\n",
    "        else:\n",
    "            sess.run(init)\n",
    "            \n",
    "        writer = tf.summary.FileWriter(tensorboard_path, sess.graph)\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            print(\"\\nEpoch {}/{}\".format(epoch, epochs))\n",
    "            batch_time = []\n",
    "            epoch_time = time.time()\n",
    "    \n",
    "            for step in range(1, data_steps + 1):\n",
    "                time_start = time.time()\n",
    "                _, batch_loss, summary = sess.run([apply_gradient_op, avg_loss, merged])\n",
    "                batch_time.append(time.time()-time_start)\n",
    "                \n",
    "                writer.add_summary(summary, ((epoch-1) * data_steps) + step)\n",
    "                \n",
    "                if (step == data_steps):\n",
    "                    sys.stdout.write(\"\\r - {}/{} - {} - loss: {:.4f}\".format(step, data_steps, get_time(time.time()-epoch_time), batch_loss))\n",
    "                else:\n",
    "                    sys.stdout.write(\"\\r - {}/{} - {} - loss: {:.4f}\".format(step, data_steps, get_time(np.mean(batch_time)*(data_steps-step)), batch_loss))\n",
    "                sys.stdout.flush()\n",
    "\n",
    "            #save model\n",
    "            if epoch % save_epoch == 0:\n",
    "                saver.save(sess, os.path.join(weight_path, \"autoencoder_loss-{}_epoch-{}\".format(batch_loss, epoch)))\n",
    "\n",
    "        #save model\n",
    "        saver.save(sess, os.path.join(weight_path, \"autoencoder_loss-{}_epoch-{}\".format(batch_loss, epoch)))\n",
    "\n",
    "        print(\"\\nFinished!\")          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Testing\n",
    "data_path = \"/home/kalvik/shared/CSI_DATA/preprocessed_final/test\"\n",
    "weight_path = \"/home/kalvik/shared/autoencoder/weights/mse/\"\n",
    "tensorboard_path = \"/home/kalvik/shared/autoencoder/tensorboard/test_mse_rollout\"\n",
    "sequence_length = 540\n",
    "input_width = 8000 \n",
    "decay_rate = 0.9\n",
    "lstm_size = 4000\n",
    "rollout_ = True\n",
    "batch_size = 8\n",
    "num_gpus = 4\n",
    "lr = 1E-4\n",
    "gen = Generator(data_path, (input_width, sequence_length), shuffle=True)\n",
    "data_steps = int(gen.num_sample//(batch_size*num_gpus))\n",
    "decay_steps = data_steps\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default(), tf.device('/cpu:0'):\n",
    "    init, merged, saver, avg_loss, apply_gradient_op, encoded_data, encoded_labels = model()\n",
    "    \n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        saver.restore(sess, tf.train.latest_checkpoint(weight_path))\n",
    "        writer = tf.summary.FileWriter(tensorboard_path, sess.graph)\n",
    "        batch_time = []\n",
    "        print(\"Started Testing\")\n",
    "\n",
    "        for step in range(1, data_steps + 1):\n",
    "            time_start = time.time()\n",
    "            batch_loss, summary = sess.run([avg_loss, merged])\n",
    "            batch_time.append(time.time()-time_start)\n",
    "\n",
    "            writer.add_summary(summary, step)\n",
    "\n",
    "            if (step == data_steps):\n",
    "                sys.stdout.write(\"\\r - {}/{} - {} - loss: {:.4f}\".format(step, data_steps, get_time(time.time()-epoch_time), batch_loss))\n",
    "            else:\n",
    "                sys.stdout.write(\"\\r - {}/{} - {} - loss: {:.4f}\".format(step, data_steps, get_time(np.mean(batch_time)*(data_steps-step)), batch_loss))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        print(\"\\nFinished!\")          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Sampling\n",
    "data_path = \"/home/kalvik/shared/CSI_DATA/preprocessed_final/test\"\n",
    "weight_path = \"/home/kalvik/shared/autoencoder/weights/mse/\"\n",
    "sequence_length = 540\n",
    "input_width = 8000 \n",
    "decay_rate = 0.9\n",
    "lstm_size = 4000\n",
    "rollout_ = True\n",
    "batch_size = 10\n",
    "num_gpus = 1\n",
    "lr = 1E-4\n",
    "gen = Generator(data_path, (input_width, sequence_length), shuffle=False)\n",
    "data_steps = int(gen.num_sample//(batch_size*num_gpus))\n",
    "decay_steps = data_steps\n",
    "\n",
    "X_data, y_data = list(), list()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default(), tf.device('/cpu:0'):\n",
    "    init, merged, saver, avg_loss, apply_gradient_op, encoded_data, encoded_labels = model()\n",
    "    \n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        saver.restore(sess, tf.train.latest_checkpoint(weight_path))\n",
    "        batch_time = []\n",
    "        print(\"Started Sampling\")\n",
    "\n",
    "        for step in range(1, data_steps + 1):\n",
    "            time_start = time.time()\n",
    "            data_temp, labels_temp = sess.run([encoded_data, encoded_labels])\n",
    "            batch_time.append(time.time()-time_start)\n",
    "\n",
    "            X_data.append(data_temp)\n",
    "            y_data.append(labels_temp)\n",
    "\n",
    "            if (step == data_steps):\n",
    "                sys.stdout.write(\"\\r - {}/{} - {}\".format(step, data_steps, get_time(time.time()-epoch_time)))\n",
    "            else:\n",
    "                sys.stdout.write(\"\\r - {}/{} - {}\".format(step, data_steps, get_time(np.mean(batch_time)*(data_steps-step))))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        print(\"\\nFinished!\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/kalvik/shared/CSI_DATA/preprocessed_final/train\"\n",
    "weight_path = \"/home/kalvik/shared/autoencoder/weights/mse/\"\n",
    "sequence_length = 540\n",
    "input_width = 8000 \n",
    "decay_rate = 0.8\n",
    "lstm_size = 4000\n",
    "rollout_ = True\n",
    "batch_size = 10\n",
    "num_gpus = 1\n",
    "lr = 1E-4\n",
    "gen = Generator(data_path, (input_width, sequence_length), shuffle=False)\n",
    "data_steps = int(gen.num_sample//(batch_size*num_gpus))\n",
    "decay_steps = data_steps\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default(), tf.device('/cpu:0'):\n",
    "    init, merged, saver, avg_loss, apply_gradient_op, encoded_data, encoded_labels = model()\n",
    "    \n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        saver.restore(sess, tf.train.latest_checkpoint(weight_path))\n",
    "        batch_time = []\n",
    "        print(\"Started Sampling\")\n",
    "\n",
    "        for step in range(1, data_steps + 1):\n",
    "            time_start = time.time()\n",
    "            data_temp, labels_temp = sess.run([encoded_data, encoded_labels])\n",
    "            batch_time.append(time.time()-time_start)\n",
    "\n",
    "            X_data.append(data_temp)\n",
    "            y_data.append(labels_temp)\n",
    "\n",
    "            if (step == data_steps):\n",
    "                sys.stdout.write(\"\\r - {}/{} - {}\".format(step, data_steps, get_time(time.time()-epoch_time)))\n",
    "            else:\n",
    "                sys.stdout.write(\"\\r - {}/{} - {}\".format(step, data_steps, get_time(np.mean(batch_time)*(data_steps-step))))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        print(\"\\nFinished!\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(X_data).shape, np.array(y_data).shape)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "autoencoder.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
