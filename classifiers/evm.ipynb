{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from model import identity_block, conv_block\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-4\n",
    "epochs=50\n",
    "decay=1e-2\n",
    "num_classes=35\n",
    "\n",
    "data_dir=\"/home/kjakkala/neuralwave/data/CSI_preprocessed_35.h5\"\n",
    "intruder_dir=\"/home/kjakkala/neuralwave/data/CSI_preprocessed_Intruder.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1189, 500, 270, 1) (200, 500, 270, 1)\n"
     ]
    }
   ],
   "source": [
    "hf = h5py.File(data_dir, 'r')\n",
    "X_train = np.expand_dims(hf.get('X_train'), axis=-1)\n",
    "X_test = np.expand_dims(hf.get('X_test'), axis=-1)\n",
    "y_train = np.array(hf.get('y_train'))\n",
    "y_test = np.array(hf.get('y_test'))\n",
    "y_train_onehot = np.eye(num_classes)[hf.get('y_train')]\n",
    "y_test_onehot = np.eye(num_classes)[hf.get('y_test')]\n",
    "hf.close()\n",
    "\n",
    "hf = h5py.File(intruder_dir, 'r')\n",
    "X_data = np.expand_dims(hf.get('X_data'), axis=-1)\n",
    "hf.close()\n",
    "\n",
    "print(X_train.shape, X_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 500, 270, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 247, 132, 64) 3200        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 247, 132, 64) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 247, 132, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 123, 65, 64)  0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 123, 65, 64)  256         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 123, 65, 64)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 62, 33, 64)   4160        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 62, 33, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 123, 65, 64)  256         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 62, 33, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 123, 65, 64)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 62, 33, 256)  147712      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 62, 33, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 62, 33, 512)  0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 62, 33, 512)  2048        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 62, 33, 512)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 62, 33, 64)   32832       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 62, 33, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 62, 33, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 62, 33, 256)  147712      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 62, 33, 768)  0           conv2d_5[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 62, 33, 768)  3072        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 62, 33, 768)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 31, 17, 128)  98432       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 31, 17, 128)  512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 62, 33, 768)  3072        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 31, 17, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 62, 33, 768)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 31, 17, 512)  590336      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 31, 17, 512)  393728      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 31, 17, 1024) 0           conv2d_7[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 31, 17, 1024) 4096        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 31, 17, 1024) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 31, 17, 128)  131200      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 31, 17, 128)  512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 31, 17, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 31, 17, 512)  590336      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 31, 17, 1536) 0           conv2d_10[0][0]                  \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 31, 17, 1536) 6144        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 31, 17, 1536) 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 9, 256)   393472      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 9, 256)   1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 31, 17, 1536) 6144        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 9, 256)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 31, 17, 1536) 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 9, 1024)  2360320     activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 9, 1024)  1573888     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 16, 9, 2048)  0           conv2d_12[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 9, 2048)  8192        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 9, 2048)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 9, 256)   524544      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 9, 256)   1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 9, 256)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 9, 1024)  2360320     activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 16, 9, 3072)  0           conv2d_15[0][0]                  \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 9, 3072)  12288       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 9, 3072)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 5, 512)    1573376     activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 5, 512)    2048        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 9, 3072)  12288       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 5, 512)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 9, 3072)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 5, 2048)   9439232     activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 8, 5, 2048)   6293504     activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 8, 5, 4096)   0           conv2d_17[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 5, 4096)   16384       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 5, 4096)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 5, 512)    2097664     activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 5, 512)    2048        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 5, 512)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 5, 2048)   9439232     activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 8, 5, 6144)   0           conv2d_20[0][0]                  \n",
      "                                                                 concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 6144)         0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 35)           215075      global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 38,509,091\n",
      "Trainable params: 38,468,003\n",
      "Non-trainable params: 41,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1189 samples, validate on 210 samples\n",
      "Epoch 1/50\n",
      " - 17s - loss: 1.7859 - acc: 0.6030 - val_loss: 4.8846 - val_acc: 0.0286\n",
      "Epoch 2/50\n",
      " - 8s - loss: 0.3260 - acc: 0.9066 - val_loss: 5.8623 - val_acc: 0.0286\n",
      "Epoch 3/50\n",
      " - 8s - loss: 0.1360 - acc: 0.9563 - val_loss: 6.6317 - val_acc: 0.0286\n",
      "Epoch 4/50\n",
      " - 8s - loss: 0.0734 - acc: 0.9790 - val_loss: 1.4672 - val_acc: 0.4857\n",
      "Epoch 5/50\n",
      " - 8s - loss: 0.0718 - acc: 0.9739 - val_loss: 0.0558 - val_acc: 0.9762\n",
      "Epoch 6/50\n",
      " - 8s - loss: 0.0458 - acc: 0.9857 - val_loss: 0.0327 - val_acc: 0.9905\n",
      "Epoch 7/50\n",
      " - 8s - loss: 0.0522 - acc: 0.9882 - val_loss: 0.0351 - val_acc: 0.9905\n",
      "Epoch 8/50\n",
      " - 8s - loss: 0.0295 - acc: 0.9916 - val_loss: 0.0356 - val_acc: 0.9905\n",
      "Epoch 9/50\n",
      " - 8s - loss: 0.0288 - acc: 0.9924 - val_loss: 0.0454 - val_acc: 0.9810\n",
      "Epoch 10/50\n",
      " - 8s - loss: 0.0201 - acc: 0.9950 - val_loss: 0.0412 - val_acc: 0.9857\n",
      "Epoch 11/50\n",
      " - 8s - loss: 0.0276 - acc: 0.9916 - val_loss: 0.0433 - val_acc: 0.9857\n",
      "Epoch 12/50\n",
      " - 8s - loss: 0.0161 - acc: 0.9966 - val_loss: 0.0345 - val_acc: 0.9810\n",
      "Epoch 13/50\n",
      " - 8s - loss: 0.0133 - acc: 0.9983 - val_loss: 0.0377 - val_acc: 0.9810\n",
      "Epoch 14/50\n",
      " - 8s - loss: 0.0140 - acc: 0.9958 - val_loss: 0.0445 - val_acc: 0.9857\n",
      "Epoch 15/50\n",
      " - 8s - loss: 0.0103 - acc: 0.9983 - val_loss: 0.0382 - val_acc: 0.9905\n",
      "Epoch 16/50\n",
      " - 8s - loss: 0.0089 - acc: 0.9983 - val_loss: 0.0387 - val_acc: 0.9857\n",
      "Epoch 17/50\n",
      " - 8s - loss: 0.0119 - acc: 0.9975 - val_loss: 0.0438 - val_acc: 0.9857\n",
      "Epoch 18/50\n",
      " - 8s - loss: 0.0139 - acc: 0.9958 - val_loss: 0.0175 - val_acc: 0.9952\n",
      "Epoch 19/50\n",
      " - 8s - loss: 0.0098 - acc: 0.9983 - val_loss: 0.0200 - val_acc: 0.9952\n",
      "Epoch 20/50\n",
      " - 8s - loss: 0.0093 - acc: 0.9983 - val_loss: 0.0206 - val_acc: 0.9905\n",
      "Epoch 21/50\n",
      " - 8s - loss: 0.0105 - acc: 0.9975 - val_loss: 0.0285 - val_acc: 0.9857\n",
      "Epoch 22/50\n",
      " - 8s - loss: 0.0075 - acc: 0.9992 - val_loss: 0.0222 - val_acc: 0.9905\n",
      "Epoch 23/50\n",
      " - 8s - loss: 0.0070 - acc: 0.9992 - val_loss: 0.0218 - val_acc: 0.9905\n",
      "Epoch 24/50\n",
      " - 8s - loss: 0.0098 - acc: 0.9966 - val_loss: 0.0188 - val_acc: 0.9905\n",
      "Epoch 25/50\n",
      " - 8s - loss: 0.0071 - acc: 0.9983 - val_loss: 0.0260 - val_acc: 0.9905\n",
      "Epoch 26/50\n",
      " - 8s - loss: 0.0056 - acc: 0.9983 - val_loss: 0.0174 - val_acc: 0.9905\n",
      "Epoch 27/50\n",
      " - 8s - loss: 0.0062 - acc: 0.9992 - val_loss: 0.0176 - val_acc: 0.9905\n",
      "Epoch 28/50\n",
      " - 8s - loss: 0.0066 - acc: 0.9983 - val_loss: 0.0199 - val_acc: 0.9952\n",
      "Epoch 29/50\n",
      " - 8s - loss: 0.0066 - acc: 0.9975 - val_loss: 0.0269 - val_acc: 0.9952\n",
      "Epoch 30/50\n",
      " - 8s - loss: 0.0076 - acc: 0.9992 - val_loss: 0.0287 - val_acc: 0.9905\n",
      "Epoch 31/50\n",
      " - 8s - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0263 - val_acc: 0.9905\n",
      "Epoch 32/50\n",
      " - 8s - loss: 0.0058 - acc: 0.9992 - val_loss: 0.0360 - val_acc: 0.9810\n",
      "Epoch 33/50\n",
      " - 8s - loss: 0.0043 - acc: 0.9992 - val_loss: 0.0285 - val_acc: 0.9857\n",
      "Epoch 34/50\n",
      " - 8s - loss: 0.0053 - acc: 0.9992 - val_loss: 0.0276 - val_acc: 0.9905\n",
      "Epoch 35/50\n",
      " - 8s - loss: 0.0081 - acc: 0.9975 - val_loss: 0.0298 - val_acc: 0.9857\n",
      "Epoch 36/50\n",
      " - 8s - loss: 0.0071 - acc: 0.9992 - val_loss: 0.0211 - val_acc: 0.9857\n",
      "Epoch 37/50\n",
      " - 8s - loss: 0.0047 - acc: 0.9992 - val_loss: 0.0254 - val_acc: 0.9905\n",
      "Epoch 38/50\n",
      " - 8s - loss: 0.0038 - acc: 0.9992 - val_loss: 0.0282 - val_acc: 0.9857\n",
      "Epoch 39/50\n",
      " - 8s - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0271 - val_acc: 0.9905\n",
      "Epoch 40/50\n",
      " - 8s - loss: 0.0044 - acc: 0.9992 - val_loss: 0.0271 - val_acc: 0.9905\n",
      "Epoch 41/50\n",
      " - 8s - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0296 - val_acc: 0.9905\n",
      "Epoch 42/50\n",
      " - 8s - loss: 0.0032 - acc: 0.9992 - val_loss: 0.0296 - val_acc: 0.9905\n",
      "Epoch 43/50\n",
      " - 8s - loss: 0.0045 - acc: 0.9992 - val_loss: 0.0273 - val_acc: 0.9905\n",
      "Epoch 44/50\n",
      " - 8s - loss: 0.0047 - acc: 0.9992 - val_loss: 0.0284 - val_acc: 0.9905\n",
      "Epoch 45/50\n",
      " - 8s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0250 - val_acc: 0.9905\n",
      "Epoch 46/50\n",
      " - 8s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0304 - val_acc: 0.9857\n",
      "Epoch 47/50\n",
      " - 8s - loss: 0.0042 - acc: 0.9992 - val_loss: 0.0327 - val_acc: 0.9857\n",
      "Epoch 48/50\n",
      " - 8s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0273 - val_acc: 0.9905\n",
      "Epoch 49/50\n",
      " - 8s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 0.9857\n",
      "Epoch 50/50\n",
      " - 8s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0307 - val_acc: 0.9905\n"
     ]
    }
   ],
   "source": [
    "input_layer = layers.Input(shape=(X_train.shape[1:]))\n",
    "\n",
    "x = layers.Conv2D(64, (7, 7), strides=(2, 2))(input_layer)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "x = conv_block(x, [64, 256], \"relu\")\n",
    "x = identity_block(x, [64, 256], \"relu\")\n",
    "\n",
    "x = conv_block(x, [128, 512], \"relu\")\n",
    "x = identity_block(x, [128, 512], \"relu\")\n",
    "\n",
    "x = conv_block(x, [256, 1024], \"relu\")\n",
    "x = identity_block(x, [256, 1024], \"relu\")\n",
    "\n",
    "x = conv_block(x, [512, 2048], \"relu\")\n",
    "x = identity_block(x, [512, 2048], \"relu\")\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(num_classes, activation=None)(x)\n",
    "x = layers.Activation('softmax')(x)\n",
    "\n",
    "model_base = Model(inputs=input_layer, outputs=x)\n",
    "model_base.summary()\n",
    "model = multi_gpu_model(model_base, gpus=3)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=lr, decay=decay), metrics=['acc'])\n",
    "history = model.fit(x=X_train, y=y_train_onehot, epochs=epochs, validation_data=(X_test, y_test_onehot), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evm = Model(inputs=model_base.get_layer(\"input_1\").input , outputs=model_base.get_layer(\"dense\").output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_evm_train = model_evm.predict(X_train)\n",
    "X_evm_test = model_evm.predict(X_test)\n",
    "X_evm_data = model_evm.predict(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1189, 35)\n"
     ]
    }
   ],
   "source": [
    "print(X_evm_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x, iters=1000, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Fits a 2-parameter Weibull distribution to the given data using maximum-likelihood estimation.\n",
    "    :param x: 1d-ndarray of samples from an (unknown) distribution. Each value must satisfy x > 0.\n",
    "    :param iters: Maximum number of iterations\n",
    "    :param eps: Stopping criterion. Fit is stopped ff the change within two iterations is smaller than eps.\n",
    "    :return: Tuple (Shape, Scale) which can be (NaN, NaN) if a fit is impossible.\n",
    "        Impossible fits may be due to 0-values in x.\n",
    "    \"\"\"\n",
    "    # fit k via MLE\n",
    "    ln_x = np.log(x+eps)\n",
    "    k = 1.\n",
    "    k_t_1 = k\n",
    "\n",
    "    for t in range(iters):\n",
    "        x_k = x ** k\n",
    "        x_k_ln_x = x_k * ln_x\n",
    "        ff = np.sum(x_k_ln_x)\n",
    "        fg = np.sum(x_k)\n",
    "        f = ff / fg - np.mean(ln_x) - (1. / k)\n",
    "\n",
    "        # Calculate second derivative d^2f/dk^2\n",
    "        ff_prime = np.sum(x_k_ln_x * ln_x)\n",
    "        fg_prime = ff\n",
    "        f_prime = (ff_prime/fg - (ff/fg * fg_prime/fg)) + (1. / (k*k))\n",
    "\n",
    "        # Newton-Raphson method k = k - f(k;x)/f'(k;x)\n",
    "        k -= f/f_prime\n",
    "\n",
    "        if np.isnan(f):\n",
    "            return np.nan, np.nan\n",
    "        if abs(k - k_t_1) < eps:\n",
    "            break\n",
    "\n",
    "        k_t_1 = k\n",
    "\n",
    "    lam = np.mean(x ** k) ** (1.0 / k)\n",
    "\n",
    "    return k, lam\n",
    "\n",
    "\n",
    "def psi_i_dist(dist, k_i, lambda_i):\n",
    "    \"\"\"\n",
    "    Gives the probability of sample inclusion\n",
    "    :param dist: Numpy vector of distances between samples\n",
    "    :param lambda_i: Scale of the Weibull fitting\n",
    "    :param k_i: Shape of the Weibull fitting\n",
    "    :return: PSI = Probability of Sample Inclusion. This is the probability that x' is included in the boundary estimated by x_i\n",
    "    \"\"\"\n",
    "    return np.exp(-(((np.abs(dist))/lambda_i)**k_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1189, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tow = 50\n",
    "weibull_models = []\n",
    "for i in range(num_classes):\n",
    "    train_ind = np.squeeze(np.where(y_train == i))\n",
    "    D = pairwise_distances(X_evm_train[train_ind], X_evm_train, metric=\"euclidean\", n_jobs=1)\n",
    "    for j in range(D.shape[0]):\n",
    "        D_tmp = np.sort(D[j])\n",
    "        D_tmp = D_tmp[np.where(D_tmp>0)][:tow]\n",
    "        weibull_models.append(fit(D_tmp, iters=100, eps=1e-6))\n",
    "weibull_models = np.array(weibull_models)\n",
    "weibull_models.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evm(data):\n",
    "    D = pairwise_distances(X_evm_train, data, metric=\"euclidean\", n_jobs=1)\n",
    "    preds = np.zeros_like(D)\n",
    "    for i in range(X_evm_train.shape[0]):\n",
    "        for j in range(data.shape[0]):\n",
    "            preds[i, j] = psi_i_dist(D[i, j], weibull_models[i][0], weibull_models[i][1])\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.04761904761905"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evm = get_evm(X_evm_test)\n",
    "np.mean(np.equal(y_train[np.argmax(evm, axis=0)], y_test))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
