{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_samples(dataset_path, endswith=\".csv\"):\n",
    "    datapaths, labels = list(), list()\n",
    "    label = 0\n",
    "    classes = sorted(os.walk(dataset_path).__next__()[1])\n",
    "    # List each sub-directory (the classes)\n",
    "    for c in classes:\n",
    "        c_dir = os.path.join(dataset_path, c)\n",
    "        walk = os.walk(c_dir).__next__()\n",
    "        # Add each image to the training set\n",
    "        for sample in walk[2]:\n",
    "            # Only keeps csv samples\n",
    "            if sample.endswith(endswith):\n",
    "                datapaths.append(os.path.join(c_dir, sample))\n",
    "                labels.append(label)\n",
    "        label += 1\n",
    "    return np.array(datapaths), np.array(labels), classes\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def convert_to(data_paths, labels, dest_path, class_name):\n",
    "    \"\"\"Converts a dataset to tfrecords.\"\"\"\n",
    "    filename = os.path.join(dest_path, class_name + '.tfrecords')\n",
    "    if not os.path.exists(os.path.join(dest_path)):\n",
    "        os.makedirs(os.path.join(dest_path))\n",
    "    \n",
    "    print('Writing', filename)\n",
    "    with tf.python_io.TFRecordWriter(filename) as writer:\n",
    "        for index in range(len(data_paths)):\n",
    "            data_raw = np.loadtxt(open(data_paths[index], \"rb\"), delimiter=\",\").astype(np.float32)\n",
    "            for i in range(540):\n",
    "                data_raw[:, i] = scalers[i].transform(np.expand_dims(data_raw[:, i], axis=0))\n",
    "            example = tf.train.Example(\n",
    "              features=tf.train.Features(\n",
    "                  feature={\n",
    "                      'label': _int64_feature(int(labels[index])),\n",
    "                      'data': _bytes_feature(data_raw.tostring())\n",
    "                  }))\n",
    "            writer.write(example.SerializeToString())\n",
    "            \n",
    "            sys.stdout.write(\"\\r{}/{}\".format(len(data_paths), index+1))\n",
    "            sys.stdout.flush()\n",
    "    print(\"\\n\")\n",
    "            \n",
    "def read_array(data_path):\n",
    "    return np.loadtxt(open(data_path, \"rb\"), delimiter=\",\")\n",
    "\n",
    "def scale_data(data_path):\n",
    "    array = np.loadtxt(open(data_path, \"rb\"), delimiter=\",\")\n",
    "    \n",
    "    for i in range(540):\n",
    "        array[:, i] = scalers[i].transform(np.expand_dims(array[:, i], axis=0))\n",
    "    \n",
    "    path, file = os.path.split(data_path)\n",
    "    _, class_name = os.path.split(path) \n",
    "        \n",
    "    np.savetxt((os.path.join(os.path.join(dest_path, class_name), file)), array.astype(np.float32), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/kalvik/Downloads\" #\"/home/kalvik/shared/CSI_DATA/preprocessed_level2/\"\n",
    "dest_path = \"/home/kalvik/Downloads/tfrecords\"#\"/home/kalvik/shared/CSI_DATA/tfrecords/\"\n",
    "\n",
    "X, y, classes = read_samples(src_path)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scalers for training data\n",
      "5/5"
     ]
    }
   ],
   "source": [
    "print(\"Calculating scalers for training data\")\n",
    "\n",
    "jobs = 16\n",
    "scalers = []\n",
    "for i in range(540):\n",
    "    scalers.append(StandardScaler())\n",
    "\n",
    "for i in range(0, len(X_train), jobs):\n",
    "    arrays = Parallel(n_jobs=jobs, verbose=0)(delayed(read_array)(addr) for addr in X_train[i:i+jobs-1])\n",
    "    arrays = np.array(arrays)\n",
    "    for j in range(540):\n",
    "        scalers[j].partial_fit(arrays[:, :, j])\n",
    "        \n",
    "    sys.stdout.write(\"\\r{}/{}\".format(len(X_train), i+arrays.shape[0]))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, num_classes):\n",
    "    indices = np.where( y_train == i )\n",
    "    os.makedirs(os.path.join(dest_path, \"train\"))\n",
    "    convert_to(X_train[indices], y_train[indices], os.path.join(dest_path, \"train\"), classes[i])\n",
    "    \n",
    "    indices = np.where( y_test == i )\n",
    "    os.makedirs(os.path.join(dest_path, \"test\"))\n",
    "    convert_to(X_test[indices], y_test[indices], os.path.join(dest_path, \"test\"), classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nScaling training data\")\n",
    "\n",
    "dest_path = \"/home/kalvik/shared/CSI_DATA/preprocessed_final/train\"\n",
    "classes = os.walk(src_path).__next__()[1]\n",
    "for class_name in classes:\n",
    "    if not os.path.exists(os.path.join(dest_path, class_name)):\n",
    "        os.makedirs(os.path.join(dest_path, class_name))\n",
    "\n",
    "jobs = 16\n",
    "for i in range(0, len(X_train), jobs):\n",
    "    Parallel(n_jobs=jobs, verbose=0)(delayed(scale_data)(addr) for addr in X_train[i:i+jobs-1])\n",
    "    \n",
    "    sys.stdout.write(\"\\r{}/{}\".format(len(X_train), i+jobs))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "print(\"\\n\\nScaling testing data\")\n",
    "\n",
    "dest_path = \"/home/kalvik/shared/CSI_DATA/preprocessed_final/test\"\n",
    "classes = os.walk(src_path).__next__()[1]\n",
    "for class_name in classes:\n",
    "    if not os.path.exists(os.path.join(dest_path, class_name)):\n",
    "        os.makedirs(os.path.join(dest_path, class_name))\n",
    "        \n",
    "jobs = 16\n",
    "for i in range(0, len(X_test), jobs):\n",
    "    Parallel(n_jobs=jobs, verbose=0)(delayed(scale_data)(addr) for addr in X_test[i:i+jobs-1])\n",
    "    \n",
    "    sys.stdout.write(\"\\r{}/{}\".format(len(X_test), i+jobs))\n",
    "    sys.stdout.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
