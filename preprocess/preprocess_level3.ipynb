{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_samples(dataset_path, endswith=\".csv\"):\n",
    "    datapaths, labels = list(), list()\n",
    "    label = 0\n",
    "    classes = sorted(os.walk(dataset_path).__next__()[1])\n",
    "    # List each sub-directory (the classes)\n",
    "    for c in classes:\n",
    "        c_dir = os.path.join(dataset_path, c)\n",
    "        walk = os.walk(c_dir).__next__()\n",
    "        # Add each image to the training set\n",
    "        for sample in walk[2]:\n",
    "            # Only keeps csv samples\n",
    "            if sample.endswith(endswith):\n",
    "                datapaths.append(os.path.join(c_dir, sample))\n",
    "                labels.append(label)\n",
    "        label += 1\n",
    "    return np.array(datapaths), np.array(labels), classes\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def convert_to(data_paths, labels, dest_path, class_name):\n",
    "    \"\"\"Converts a dataset to tfrecords.\"\"\"\n",
    "    filename = os.path.join(dest_path, class_name + '.tfrecords')\n",
    "    if not os.path.exists(os.path.join(dest_path)):\n",
    "        os.makedirs(os.path.join(dest_path))\n",
    "    \n",
    "    print('Writing', filename)\n",
    "    with tf.python_io.TFRecordWriter(filename) as writer:\n",
    "        for index in range(len(data_paths)):\n",
    "            data_raw = np.loadtxt(open(data_paths[index], \"rb\"), delimiter=\",\").astype(np.float32)\n",
    "            for i in range(540):\n",
    "                data_raw[:, i] = scalers[i].transform(np.expand_dims(data_raw[:, i], axis=0))\n",
    "            data_raw = (data_raw-min_)/rng\n",
    "    \n",
    "            example = tf.train.Example(\n",
    "              features=tf.train.Features(\n",
    "                  feature={\n",
    "                      'label': _int64_feature(int(labels[index])),\n",
    "                      'data': _bytes_feature(data_raw.tostring())\n",
    "                  }))\n",
    "            writer.write(example.SerializeToString())\n",
    "            \n",
    "            sys.stdout.write(\"\\r{}/{}\".format(len(data_paths), index+1))\n",
    "            sys.stdout.flush()\n",
    "    print(\"\\n\")\n",
    "            \n",
    "def read_array(data_path):\n",
    "    return np.loadtxt(open(data_path, \"rb\"), delimiter=\",\")\n",
    "\n",
    "def scale_data(data_path):\n",
    "    array = np.loadtxt(open(data_path, \"rb\"), delimiter=\",\")\n",
    "    \n",
    "    for i in range(540):\n",
    "        array[:, i] = scalers[i].transform(np.expand_dims(array[:, i], axis=0))\n",
    "    \n",
    "    path, file = os.path.split(data_path)\n",
    "    _, class_name = os.path.split(path) \n",
    "        \n",
    "    np.savetxt((os.path.join(os.path.join(dest_path, class_name), file)), array.astype(np.float32), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/kalvik/shared/CSI_DATA/preprocessed_level2/\"\n",
    "dest_path = \"/home/kalvik/shared/CSI_DATA/tfrecords/\"\n",
    "\n",
    "X, y, classes = read_samples(src_path)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1096 194\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scalers for training data\n",
      "1096/1096"
     ]
    }
   ],
   "source": [
    "print(\"Calculating scalers for training data\")\n",
    "\n",
    "jobs = 16\n",
    "scalers = []\n",
    "min_ = float('Inf')\n",
    "max_ = -float('Inf')\n",
    "for i in range(540):\n",
    "    scalers.append(StandardScaler(with_std = False))\n",
    "\n",
    "for i in range(0, len(X_train), jobs):\n",
    "    arrays = Parallel(n_jobs=jobs, verbose=0)(delayed(read_array)(addr) for addr in X_train[i:i+jobs-1])\n",
    "    arrays = np.array(arrays)\n",
    "    min_temp = np.min(arrays)\n",
    "    max_temp = np.max(arrays)\n",
    "    min_ = min(min_temp, min_)\n",
    "    max_ = max(max_temp, max_)\n",
    "\n",
    "    for j in range(540):\n",
    "        scalers[j].partial_fit(arrays[:, :, j])\n",
    "        \n",
    "    sys.stdout.write(\"\\r{}/{}\".format(len(X_train), i+arrays.shape[0]))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/akarsh.tfrecords\n",
      "36/36\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/akarsh.tfrecords\n",
      "4/4\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/anil.tfrecords\n",
      "28/28\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/anil.tfrecords\n",
      "12/12\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/bivor.tfrecords\n",
      "35/35\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/bivor.tfrecords\n",
      "5/5\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/bruno.tfrecords\n",
      "37/37\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/bruno.tfrecords\n",
      "3/3\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/carson.tfrecords\n",
      "34/34\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/carson.tfrecords\n",
      "6/6\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/champ.tfrecords\n",
      "32/32\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/champ.tfrecords\n",
      "8/8\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/cheng.tfrecords\n",
      "33/33\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/cheng.tfrecords\n",
      "7/7\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/dawson_heide.tfrecords\n",
      "50/50\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/dawson_heide.tfrecords\n",
      "9/9\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/ding.tfrecords\n",
      "31/31\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/ding.tfrecords\n",
      "9/9\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/donglin.tfrecords\n",
      "35/35\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/donglin.tfrecords\n",
      "5/5\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/greyson.tfrecords\n",
      "33/33\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/greyson.tfrecords\n",
      "7/7\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/jingwei.tfrecords\n",
      "32/32\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/jingwei.tfrecords\n",
      "8/8\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/kailey_wolfe.tfrecords\n",
      "49/49\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/kailey_wolfe.tfrecords\n",
      "11/11\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/karena_huang.tfrecords\n",
      "45/45\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/karena_huang.tfrecords\n",
      "9/9\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/kerwin_mercude.tfrecords\n",
      "52/52\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/kerwin_mercude.tfrecords\n",
      "6/6\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/mark_powers.tfrecords\n",
      "52/52\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/mark_powers.tfrecords\n",
      "8/8\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/marquaez.tfrecords\n",
      "35/35\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/marquaez.tfrecords\n",
      "5/5\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/nathan.tfrecords\n",
      "36/36\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/nathan.tfrecords\n",
      "4/4\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/nikhil.tfrecords\n",
      "37/37\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/nikhil.tfrecords\n",
      "3/3\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/prabhu.tfrecords\n",
      "34/34\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/prabhu.tfrecords\n",
      "6/6\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/safat.tfrecords\n",
      "35/35\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/safat.tfrecords\n",
      "5/5\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/sam.tfrecords\n",
      "36/36\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/sam.tfrecords\n",
      "4/4\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/siddu.tfrecords\n",
      "35/35\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/siddu.tfrecords\n",
      "5/5\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/siqi.tfrecords\n",
      "31/31\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/siqi.tfrecords\n",
      "9/9\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/sneha.tfrecords\n",
      "33/33\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/sneha.tfrecords\n",
      "7/7\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/sultan.tfrecords\n",
      "33/33\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/sultan.tfrecords\n",
      "6/6\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/ting.tfrecords\n",
      "35/35\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/ting.tfrecords\n",
      "5/5\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/trinadh.tfrecords\n",
      "35/35\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/trinadh.tfrecords\n",
      "5/5\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/wahida.tfrecords\n",
      "36/36\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/wahida.tfrecords\n",
      "4/4\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/train/wei.tfrecords\n",
      "31/31\n",
      "\n",
      "Writing /home/kalvik/shared/CSI_DATA/tfrecords/test/wei.tfrecords\n",
      "9/9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rng = max_ - min_\n",
    "for i in range(num_classes):\n",
    "    indices = np.where( y_train == i )\n",
    "    if not os.path.exists(os.path.join(dest_path, \"train\")):\n",
    "        os.makedirs(os.path.join(dest_path, \"train\"))\n",
    "    convert_to(X_train[indices], y_train[indices], os.path.join(dest_path, \"train\"), classes[i])\n",
    "    \n",
    "    indices = np.where( y_test == i )\n",
    "    if not os.path.exists(os.path.join(dest_path, \"test\")):\n",
    "        os.makedirs(os.path.join(dest_path, \"test\"))\n",
    "    convert_to(X_test[indices], y_test[indices], os.path.join(dest_path, \"test\"), classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nScaling training data\")\n",
    "\n",
    "dest_path = \"/home/kalvik/shared/CSI_DATA/preprocessed_final/train\"\n",
    "classes = os.walk(src_path).__next__()[1]\n",
    "for class_name in classes:\n",
    "    if not os.path.exists(os.path.join(dest_path, class_name)):\n",
    "        os.makedirs(os.path.join(dest_path, class_name))\n",
    "\n",
    "jobs = 16\n",
    "for i in range(0, len(X_train), jobs):\n",
    "    Parallel(n_jobs=jobs, verbose=0)(delayed(scale_data)(addr) for addr in X_train[i:i+jobs-1])\n",
    "    \n",
    "    sys.stdout.write(\"\\r{}/{}\".format(len(X_train), i+jobs))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "print(\"\\n\\nScaling testing data\")\n",
    "\n",
    "dest_path = \"/home/kalvik/shared/CSI_DATA/preprocessed_final/test\"\n",
    "classes = os.walk(src_path).__next__()[1]\n",
    "for class_name in classes:\n",
    "    if not os.path.exists(os.path.join(dest_path, class_name)):\n",
    "        os.makedirs(os.path.join(dest_path, class_name))\n",
    "        \n",
    "jobs = 16\n",
    "for i in range(0, len(X_test), jobs):\n",
    "    Parallel(n_jobs=jobs, verbose=0)(delayed(scale_data)(addr) for addr in X_test[i:i+jobs-1])\n",
    "    \n",
    "    sys.stdout.write(\"\\r{}/{}\".format(len(X_test), i+jobs))\n",
    "    sys.stdout.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
