{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv1D, Flatten, Dropout, MaxPooling1D, Dense, BatchNormalization, Activation, UpSampling1D, Concatenate\n",
    "from keras.utils.np_utils import to_categorical   \n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_x, data_y, l1, l2):\n",
    "    data_x_temp, data_y_temp = list(), list()\n",
    "    for i in range(data_x.shape[0]):\n",
    "        if data_y[i] == l1:\n",
    "            data_y_temp.append(0)\n",
    "            data_x_temp.append(data_x[i])\n",
    "        elif data_y[i] == l2:\n",
    "            data_y_temp.append(1)\n",
    "            data_x_temp.append(data_x[i])\n",
    "            \n",
    "    return np.expand_dims(data_x_temp, axis=2), np.array(data_y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('preprocessed.h5', 'r')\n",
    "X_train = np.array(hf.get('X_train'))\n",
    "X_test = np.array(hf.get('X_test'))\n",
    "y_train = np.array(hf.get('y_train'))\n",
    "y_test = np.array(hf.get('y_test'))\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train on 65 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 1.1611 - acc: 0.4769 - val_loss: 0.0133 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.1336 - acc: 0.9692 - val_loss: 0.0200 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0248 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0125 - acc: 1.0000 - val_loss: 5.9657e-04 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0028 - acc: 1.0000 - val_loss: 4.3957e-04 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0018 - acc: 1.0000 - val_loss: 7.0395e-04 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0015 - acc: 1.0000 - val_loss: 6.2072e-04 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 5.4681e-04 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0010 - acc: 1.0000 - val_loss: 2.9697e-04 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      " - 0s - loss: 8.0102e-04 - acc: 1.0000 - val_loss: 2.0667e-04 - val_acc: 1.0000\n",
      "\n",
      "Train on 72 samples, validate on 8 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.3736 - acc: 0.8056 - val_loss: 0.1284 - val_acc: 0.8750\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0810 - acc: 0.9583 - val_loss: 0.7142 - val_acc: 0.7500\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0306 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 2.3504e-05 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0069 - acc: 1.0000 - val_loss: 3.9242e-06 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      " - 0s - loss: 5.3026e-04 - acc: 1.0000 - val_loss: 3.1362e-06 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      " - 0s - loss: 8.8344e-05 - acc: 1.0000 - val_loss: 3.8730e-06 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      " - 0s - loss: 6.7407e-05 - acc: 1.0000 - val_loss: 5.3191e-06 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 8.4268e-05 - acc: 1.0000 - val_loss: 8.0455e-06 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      " - 0s - loss: 9.5136e-05 - acc: 1.0000 - val_loss: 1.2064e-05 - val_acc: 1.0000\n",
      "\n",
      "Train on 69 samples, validate on 11 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.7966 - acc: 0.6522 - val_loss: 1.5383 - val_acc: 0.6364\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.1809 - acc: 0.9565 - val_loss: 0.7608 - val_acc: 0.6364\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0341 - acc: 1.0000 - val_loss: 0.3518 - val_acc: 0.8182\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0101 - acc: 1.0000 - val_loss: 0.2505 - val_acc: 0.8182\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0073 - acc: 1.0000 - val_loss: 0.1239 - val_acc: 0.9091\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0611 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0271 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 8.2984e-04 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      " - 0s - loss: 4.6115e-04 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "\n",
      "Train on 61 samples, validate on 19 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.5472 - acc: 0.7049 - val_loss: 0.2172 - val_acc: 0.9474\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0339 - acc: 1.0000 - val_loss: 0.1327 - val_acc: 0.9474\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0835 - val_acc: 0.9474\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0456 - val_acc: 0.9474\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0197 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      " - 0s - loss: 9.5480e-04 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.3615e-04 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      " - 0s - loss: 5.3265e-04 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 5.4091e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      " - 0s - loss: 2.9793e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "\n",
      "Train on 72 samples, validate on 8 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 1.4499 - acc: 0.3750 - val_loss: 0.2942 - val_acc: 0.8750\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.1483 - acc: 0.9722 - val_loss: 0.1805 - val_acc: 0.8750\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0359 - acc: 1.0000 - val_loss: 0.0344 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0264 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0136 - acc: 1.0000 - val_loss: 0.0240 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0458 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0611 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0679 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0641 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0548 - val_acc: 1.0000\n",
      "\n",
      "Train on 73 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.6567 - acc: 0.6438 - val_loss: 0.3922 - val_acc: 0.7143\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.1918 - acc: 0.9589 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0435 - acc: 0.9863 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0169 - acc: 1.0000 - val_loss: 5.1822e-04 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0280 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0122 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0045 - acc: 1.0000 - val_loss: 4.6562e-04 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 8.7300e-05 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 8.6250e-04 - acc: 1.0000 - val_loss: 4.2088e-05 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      " - 0s - loss: 6.7470e-04 - acc: 1.0000 - val_loss: 3.2789e-05 - val_acc: 1.0000\n",
      "\n",
      "Train on 65 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.6825 - acc: 0.6615 - val_loss: 0.4988 - val_acc: 0.8667\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.2149 - acc: 0.9231 - val_loss: 0.1673 - val_acc: 0.9333\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0678 - acc: 0.9846 - val_loss: 0.0182 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0478 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0104 - acc: 1.0000 - val_loss: 6.1734e-04 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0055 - acc: 1.0000 - val_loss: 1.0079e-04 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0020 - acc: 1.0000 - val_loss: 3.4329e-05 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 4.5708e-05 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.9226e-04 - acc: 1.0000 - val_loss: 1.1740e-04 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      " - 0s - loss: 8.8996e-04 - acc: 1.0000 - val_loss: 1.3489e-04 - val_acc: 1.0000\n",
      "\n",
      "Train on 66 samples, validate on 14 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 0.5697 - acc: 0.6667 - val_loss: 1.2765 - val_acc: 0.5714\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0731 - acc: 0.9697 - val_loss: 0.0504 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0732 - acc: 0.9848 - val_loss: 0.0367 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0199 - acc: 1.0000 - val_loss: 0.2996 - val_acc: 0.8571\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0140 - acc: 1.0000 - val_loss: 0.7111 - val_acc: 0.6429\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0153 - acc: 1.0000 - val_loss: 0.6430 - val_acc: 0.6429\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0079 - acc: 1.0000 - val_loss: 0.1951 - val_acc: 0.9286\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0724 - val_acc: 0.9286\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0360 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0315 - val_acc: 1.0000\n",
      "\n",
      "Train on 69 samples, validate on 11 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 0.7415 - acc: 0.5797 - val_loss: 1.3461 - val_acc: 0.4545\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.1585 - acc: 0.9420 - val_loss: 0.1116 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0171 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0127 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0176 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0194 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      " - 0s - loss: 9.9539e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "\n",
      "Train on 72 samples, validate on 8 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.6337 - acc: 0.6389 - val_loss: 0.1266 - val_acc: 0.8750\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0509 - acc: 0.9861 - val_loss: 0.0163 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0495 - acc: 0.9722 - val_loss: 2.7778e-04 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0043 - acc: 1.0000 - val_loss: 8.5270e-04 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0023 - acc: 1.0000 - val_loss: 2.9696e-04 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0010 - acc: 1.0000 - val_loss: 8.2384e-05 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.1465e-04 - acc: 1.0000 - val_loss: 3.6980e-05 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      " - 0s - loss: 5.3476e-04 - acc: 1.0000 - val_loss: 2.2791e-05 - val_acc: 1.0000\n",
      "\n",
      "Train on 65 samples, validate on 14 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 1.1634 - acc: 0.4769 - val_loss: 0.5312 - val_acc: 0.7857\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.1667 - acc: 0.9538 - val_loss: 0.8288 - val_acc: 0.4286\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.1370 - acc: 1.0000 - val_loss: 0.1901 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.1523 - acc: 0.9385 - val_loss: 0.1020 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0934 - acc: 0.9692 - val_loss: 0.0174 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0210 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0309 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0127 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "\n",
      "Train on 67 samples, validate on 13 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.6069 - acc: 0.6716 - val_loss: 1.8018 - val_acc: 0.6154\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.4861 - acc: 0.7164 - val_loss: 0.0895 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0457 - acc: 1.0000 - val_loss: 0.0206 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0169 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0151 - acc: 1.0000 - val_loss: 3.3939e-04 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0079 - acc: 1.0000 - val_loss: 2.8809e-04 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0034 - acc: 1.0000 - val_loss: 4.5277e-04 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0030 - acc: 1.0000 - val_loss: 4.8542e-04 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0020 - acc: 1.0000 - val_loss: 1.0640e-04 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 4.6210e-05 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for labels in range(0, 24, 2):\n",
    "    print(\"\")\n",
    "    \n",
    "    X_train_temp, y_train_temp = get_data(X_train, y_train, labels, labels+1)\n",
    "    X_test_temp, y_test_temp = get_data(X_test, y_test, labels, labels+1)\n",
    "\n",
    "    inputs = Input(shape=(X_train_temp.shape[-2], 1))\n",
    "\n",
    "    x = Conv1D(16, 17, strides=1, padding='same')(inputs)\n",
    "    x = BatchNormalization(axis = -1)(x)\n",
    "    x = Activation('selu')(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    x = Conv1D(16, 11, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization(axis = -1)(x)\n",
    "    x = Activation('selu')(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    x = Conv1D(16, 11, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization(axis = -1)(x)\n",
    "    x = Activation('selu')(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    x = Conv1D(16, 7, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization(axis = -1)(x)\n",
    "    x = Activation('selu')(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    x = Conv1D(16, 7, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization(axis = -1)(x)\n",
    "    x = Activation('selu')(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1, activation='linear')(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "\n",
    "    models.append(Model(inputs=inputs, outputs=x))\n",
    "    models[-1].compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=1e-2, decay=1e-5), metrics=['acc'])\n",
    "    models[-1].fit(x=X_train_temp, y=y_train_temp, epochs=10, validation_data=(X_test_temp, y_test_temp), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0\n",
      "10 0\n",
      "10 0\n",
      "10 0\n",
      "14 1\n",
      "14 1\n",
      "14 1\n",
      "14 1\n",
      "14 1\n",
      "14 1\n",
      "14 1\n"
     ]
    }
   ],
   "source": [
    "def predict(x, models):\n",
    "    preds = []\n",
    "    for i in range(len(models)):\n",
    "        preds.append(models[i].predict(np.reshape(x, (1, 333, 1))))\n",
    "        \n",
    "    if (np.min(preds) < (1-np.min(preds))):\n",
    "        return np.argmin(preds)*2\n",
    "    else:\n",
    "        return (np.argmax(preds)*2)+1\n",
    "\n",
    "X_test_temp, y_test_temp = get_data(X_test, y_test, 4, 5)\n",
    "\n",
    "y_pred = []\n",
    "for i in range(X_test_temp.shape[0]):\n",
    "    print(predict(X_test_temp[i], models), y_test_temp[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
