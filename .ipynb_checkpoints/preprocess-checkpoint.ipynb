{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "#dataset_gdrive = https://drive.google.com/open?id=0B6FZBAhUFX8OaUJZRDkzaFVJQlk\n",
    "\n",
    "src_dir = './dataset'\n",
    "dest_file = './dataset/data.h5'\n",
    "\n",
    "names = ['abhishek', 'ahmad', 'akarsh', 'avatar', 'chaitanya', 'champ', 'harshith', 'ishan',\n",
    "       'kalvik', 'manish', 'nishad', 'pavan', 'phani', 'prabhu', 'raghu', 'rahul', 'sanjay', 'shuang',\n",
    "       'subramaniam', 'sushal', 'temesgen', 'vinay']\n",
    "\n",
    "num_people = len(names)\n",
    "num_rows = 90000\n",
    "val_split = 0.20\n",
    "num_obs = 15\n",
    "val_num = int((val_split*num_people*num_obs)/num_people)\n",
    "num_cols = 6\n",
    "n_steps = num_rows * num_obs\n",
    "num_aug_ops = 5\n",
    "total_data_steps = num_rows * num_obs * num_aug_ops\n",
    "mean_noise = 0\n",
    "std_noise = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging csv\n",
      "preparing data for  abhishek\n",
      "preparing data for  ahmad\n",
      "preparing data for  akarsh\n",
      "preparing data for  avatar\n",
      "preparing data for  chaitanya\n",
      "preparing data for  champ\n",
      "preparing data for  harshith\n",
      "preparing data for  ishan\n",
      "preparing data for  kalvik\n",
      "preparing data for  manish\n",
      "preparing data for  nishad\n",
      "preparing data for  pavan\n",
      "preparing data for  phani\n",
      "preparing data for  prabhu\n",
      "preparing data for  raghu\n",
      "preparing data for  rahul\n",
      "preparing data for  sanjay\n",
      "preparing data for  shuang\n",
      "preparing data for  subramaniam\n",
      "preparing data for  sushal\n",
      "preparing data for  temesgen\n",
      "preparing data for  vinay\n"
     ]
    }
   ],
   "source": [
    "print(\"merging csv\")\n",
    "\n",
    "val_x = []\n",
    "val_y = []\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "for index, name in enumerate(names):\n",
    "    print('preparing data for ', name)\n",
    "\n",
    "    filenames = []\n",
    "    for i in range(1,num_obs+1):\n",
    "        filenames.append(src_dir + '/{0}/{0}{1}.csv'.format(name, i))\n",
    "    \n",
    "    dfs = []\n",
    "    for filename in filenames:\n",
    "        df = np.array(pd.read_csv(filename))\n",
    "        df = df[0:num_rows, :]\n",
    "        if (df.shape[0] != 90000):\n",
    "            print (filename)\n",
    "        dfs.append(df)\n",
    "        \n",
    "    shuffle(dfs)    \n",
    "    val_x.extend(dfs[:val_num])\n",
    "    train_x.extend(dfs[val_num:])\n",
    "    val_y.extend(index for _ in range(val_num))\n",
    "    train_y.extend(index for _ in range(num_obs - val_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320 1320\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(train_x)):\n",
    "    mag = train_x[i][:, :3]\n",
    "    phase = train_x[i][:, 3:]\n",
    "    \n",
    "    flip_lr_mag = np.fliplr(mag)\n",
    "    flip_lr_phase = np.fliplr(phase)\n",
    "    \n",
    "    flip_join = np.hstack((flip_lr_mag, flip_lr_phase))\n",
    "\n",
    "    flip_updown = np.flipud(train_x[i])\n",
    "    \n",
    "    flip_combo = np.flipud(flip_join)\n",
    "    \n",
    "    gaussian_noise = np.random.normal(mean_noise, std_noise, [num_rows, num_cols])\n",
    "    \n",
    "    data_corrupt = train_x[i] + gaussian_noise\n",
    "    \n",
    "    train_x.append(flip_join)\n",
    "    train_x.append(flip_updown)\n",
    "    train_x.append(flip_combo)\n",
    "    train_x.append(data_corrupt)\n",
    "    \n",
    "    train_y.extend(train_y[i] for _ in range(4))\n",
    "    \n",
    "print(len(train_y), len(train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 90000, 6) (66,) (1320, 90000, 6) (1320,)\n"
     ]
    }
   ],
   "source": [
    "val_x = np.array(val_x)\n",
    "val_y = np.array(val_y)\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "print (val_x.shape, val_y.shape, train_x.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File(dest_file, 'w')\n",
    "hf.create_dataset('train_x', data=train_x)\n",
    "hf.create_dataset('train_y', data=train_y)\n",
    "hf.create_dataset('val_x', data=val_x)\n",
    "hf.create_dataset('val_y', data=val_y)\n",
    "hf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
